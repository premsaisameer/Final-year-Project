# -*- coding: utf-8 -*-
"""win_prediction_NN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Zs8MJFAePkH9_Ev8BYaGWN5K77NSq-PI
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

import torch

torch.manual_seed(0)

matches = pd.read_csv("final_new_matches.csv")

prediction_df = matches[
    ["team1", "team2", "team1_toss_win", "team1_bat", "team1_win", "venue", "team1_score", "team2_score"]]

# feature selection
X = prediction_df.drop('team1_win', axis=1)
target = prediction_df['team1_win']
target = target.astype(int)

# Splitting the data into training and testing data and scaling it
X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.2, random_state=0)
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

X_train, X_test, Y_train, Y_test = train_test_split(X, target, test_size=0.2, stratify=target, random_state=0)
print(X_train.shape, X_test.shape, target.shape)
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

# X_train, Y_train, X_val, Y_val = map(torch.tensor, (X_train, Y_train, X_val, Y_val))

X_train = torch.tensor(X_train)
X_test = torch.tensor(X_test)
Y_train = torch.from_numpy(np.array(Y_train)).type(torch.LongTensor)
Y_test = torch.from_numpy(np.array(Y_test)).type(torch.LongTensor)
print(Y_train.shape, Y_test.shape)

"""Using NN.Sequential"""

from torch import optim
import torch.nn as nn
import torch.nn.functional as F


class FirstNetwork_v2(nn.Module):

    def __init__(self):
        super().__init__()
        torch.manual_seed(0)
        self.net = nn.Sequential(
            nn.Linear(7, 10),  # (649 ,7) x (7,10) -> (649,10)
            nn.ReLU(),  # (649,10)
            nn.Linear(10, 10),  # (649,10) x (10,10) -> (649,10)
            nn.ReLU(),  # (649,10)
            nn.Linear(10, 10),  # (649,10) x (10,10) -> (649,10)
            nn.ReLU(),
            nn.Linear(10, 1),  # (649,10) x (10,1)
            nn.Sigmoid()  # (649,1)
        )

    def forward(self, X):
        return self.net(X)


def accuracy(y_hat, y):
    pred = torch.argmax(y_hat, dim=1)
    return (pred == y).float().mean()


def fit(x, y, model, opt, loss_fn, epochs=1000):
    loss_arr = []
    acc_arr = []
    for epoch in range(epochs):
        y_hat = model(x.float())
        y = y.view(649, 1).float()
        loss = loss_fn(y_hat, y)
        loss.backward()
        loss_arr.append(loss.item())
        acc_arr.append(accuracy(y_hat, y))
        opt.step()
        opt.zero_grad()
    plt.plot(loss_arr, 'r-')
    plt.plot(acc_arr, 'b-')
    plt.show()
    print('Loss before training', loss_arr[0])
    print('Loss after training', loss_arr[-1])
    print('Accuracy after training', acc_arr[-1])
    return loss.item()


fn = FirstNetwork_v2()
loss_fn = nn.BCELoss()
opt = optim.Adam(fn.parameters(), lr=0.001, weight_decay=1e-5)
fit(X_train, Y_train, fn, opt, loss_fn)

"""Evaluation"""

fn.eval()
y_pred = fn(X_test.float())
y = Y_test.view(163, 1).float()
after_train = loss_fn(y_pred, y)
print("Accuracy on The Test Data", accuracy(y_pred, y))
print('Test loss after Training', after_train.item())
